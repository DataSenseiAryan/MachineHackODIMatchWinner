{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../MachineHackODIMatchWinner/Train.csv\")\n",
    "test = pd.read_csv(\"../MachineHackODIMatchWinner/Test.csv\")\n",
    "sf = pd.read_excel(\"../MachineHackODIMatchWinner/Sample_submission.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalabelencoder(train,test,cols):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    label_enc = LabelEncoder()\n",
    "    \n",
    "    print(cols)\n",
    "    for col in cols:\n",
    "        label_enc.fit(train[col])\n",
    "        train[col] = label_enc.transform(train[col])\n",
    "        test[col] = label_enc.transform(test[col])\n",
    "    \n",
    "    return train,test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onhotencoder(train,test,cols):\n",
    "    \n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    #object_cols = catVar1(train) #catVar1 gives desired categorical column and not all object columns\n",
    "    object_cols=cols\n",
    "    print(object_cols)\n",
    "    \n",
    "    OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train[object_cols]))\n",
    "    OH_cols_test = pd.DataFrame(OH_encoder.transform(test[object_cols]))\n",
    "\n",
    "    # One-hot encoding removed index; put it back\n",
    "    OH_cols_train.index = train.index\n",
    "    OH_cols_test.index = test.index\n",
    "\n",
    "    ##hack for restoring columns names just like get dummies\n",
    "    column_name = OH_encoder.get_feature_names(object_cols)\n",
    "    OH_cols_train.columns = column_name\n",
    "    OH_cols_test.columns = column_name\n",
    "    \n",
    "\n",
    "    # Remove desired categorical columns (will replace with one-hot encoding)\n",
    "    num_train = train.drop(object_cols, axis=1)\n",
    "    num_test = test.drop(object_cols, axis=1)\n",
    "\n",
    "    # Add one-hot encoded columns to numerical/remaining features\n",
    "    OH_train = pd.concat([num_train, OH_cols_train], axis=1)\n",
    "    OH_test = pd.concat([num_test, OH_cols_test], axis=1)\n",
    "    \n",
    "    print(OH_train.shape,OH_test.shape)\n",
    "    \n",
    "    \n",
    "    return OH_train,OH_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Team1_Venue', 'Team2_Venue', 'Team1_Innings', 'Team2_Innings', 'MonthOfMatch']\n"
     ]
    }
   ],
   "source": [
    "trainlblohe ,testlblohe = normalabelencoder(train,test, cols = [ 'Team1_Venue',\n",
    "       'Team2_Venue', 'Team1_Innings', 'Team2_Innings', 'MonthOfMatch']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = trainlblohe.MatchWinner\n",
    "\n",
    "X = trainlblohe.drop(['MatchWinner'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Create the example dataset and split it.\n",
    "np.random.seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "X_ros, y_ros = ros.fit_sample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2= RandomForestClassifier(random_state=2)\n",
    "\n",
    "\n",
    "clf_sigmoid = CalibratedClassifierCV(clf2, cv=5, method='sigmoid')\n",
    "clf_sigmoid.fit(X_ros, y_ros)\n",
    "preds = clf_sigmoid.predict_proba(testlblohe)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1075, 16)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_sigmoid.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = pd.read_excel(\"../MachineHackODIMatchWinner/Sample_submission.xlsx\")\n",
    "prediction = pd.DataFrame(data =preds, columns=sf.columns)\n",
    "prediction.to_excel('../MachineHackODIMatchWinner/cajokesigmoidros.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.015994</td>\n",
       "      <td>0.888352</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.011880</td>\n",
       "      <td>0.013816</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.014971</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>0.009440</td>\n",
       "      <td>0.010510</td>\n",
       "      <td>0.005714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003062</td>\n",
       "      <td>0.743703</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.047662</td>\n",
       "      <td>0.017785</td>\n",
       "      <td>0.003224</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.013082</td>\n",
       "      <td>0.018207</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.012184</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.110140</td>\n",
       "      <td>0.008348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.014721</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.010553</td>\n",
       "      <td>0.013579</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.013296</td>\n",
       "      <td>0.902405</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>0.010766</td>\n",
       "      <td>0.011786</td>\n",
       "      <td>0.005648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003155</td>\n",
       "      <td>0.022251</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.014484</td>\n",
       "      <td>0.019463</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.315781</td>\n",
       "      <td>0.525802</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.009706</td>\n",
       "      <td>0.019463</td>\n",
       "      <td>0.050118</td>\n",
       "      <td>0.008019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.015603</td>\n",
       "      <td>0.676494</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>0.093106</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.010688</td>\n",
       "      <td>0.022869</td>\n",
       "      <td>0.039899</td>\n",
       "      <td>0.077405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>0.002293</td>\n",
       "      <td>0.014896</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.010532</td>\n",
       "      <td>0.884245</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>0.013924</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>0.012230</td>\n",
       "      <td>0.010814</td>\n",
       "      <td>0.027298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>0.002696</td>\n",
       "      <td>0.632589</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.011060</td>\n",
       "      <td>0.014190</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.012046</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.271722</td>\n",
       "      <td>0.012369</td>\n",
       "      <td>0.012310</td>\n",
       "      <td>0.006221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>0.002539</td>\n",
       "      <td>0.016321</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.862866</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.019710</td>\n",
       "      <td>0.037409</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.013090</td>\n",
       "      <td>0.011388</td>\n",
       "      <td>0.011262</td>\n",
       "      <td>0.006253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>0.005165</td>\n",
       "      <td>0.031933</td>\n",
       "      <td>0.004541</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.020592</td>\n",
       "      <td>0.032246</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>0.002546</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.032879</td>\n",
       "      <td>0.386263</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.165849</td>\n",
       "      <td>0.266371</td>\n",
       "      <td>0.029094</td>\n",
       "      <td>0.012111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>0.002967</td>\n",
       "      <td>0.019925</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.020015</td>\n",
       "      <td>0.130084</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.753440</td>\n",
       "      <td>0.019163</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.009603</td>\n",
       "      <td>0.013708</td>\n",
       "      <td>0.013560</td>\n",
       "      <td>0.007205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1075 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.002348  0.015994  0.888352  0.000829  0.011880  0.013816  0.002459   \n",
       "1     0.003062  0.743703  0.004112  0.001128  0.047662  0.017785  0.003224   \n",
       "2     0.002287  0.014721  0.002146  0.000836  0.010553  0.013579  0.002420   \n",
       "3     0.003155  0.022251  0.003135  0.001173  0.014484  0.019463  0.003492   \n",
       "4     0.004591  0.030142  0.003695  0.001375  0.015603  0.676494  0.003971   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1070  0.002293  0.014896  0.002138  0.000827  0.010532  0.884245  0.002446   \n",
       "1071  0.002696  0.632589  0.002334  0.000931  0.011060  0.014190  0.002734   \n",
       "1072  0.002539  0.016321  0.002259  0.000882  0.010500  0.862866  0.002593   \n",
       "1073  0.005165  0.031933  0.004541  0.001772  0.020592  0.032246  0.005305   \n",
       "1074  0.002967  0.019925  0.002749  0.001040  0.020015  0.130084  0.003069   \n",
       "\n",
       "            7         8         9         10        11        12        13  \\\n",
       "0     0.001203  0.000793  0.014971  0.013200  0.000759  0.007731  0.009440   \n",
       "1     0.001649  0.001075  0.013082  0.018207  0.001002  0.012184  0.013636   \n",
       "2     0.001187  0.000780  0.013296  0.902405  0.000745  0.006844  0.010766   \n",
       "3     0.001748  0.001113  0.315781  0.525802  0.001098  0.009706  0.019463   \n",
       "4     0.001915  0.001311  0.015671  0.093106  0.001266  0.010688  0.022869   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1070  0.001202  0.000789  0.008991  0.013924  0.000753  0.006621  0.012230   \n",
       "1071  0.001363  0.000897  0.012046  0.015686  0.000852  0.271722  0.012369   \n",
       "1072  0.001277  0.000845  0.019710  0.037409  0.000806  0.013090  0.011388   \n",
       "1073  0.002546  0.001700  0.032879  0.386263  0.001634  0.165849  0.266371   \n",
       "1074  0.001505  0.001015  0.753440  0.019163  0.000953  0.009603  0.013708   \n",
       "\n",
       "            14        15  \n",
       "0     0.010510  0.005714  \n",
       "1     0.110140  0.008348  \n",
       "2     0.011786  0.005648  \n",
       "3     0.050118  0.008019  \n",
       "4     0.039899  0.077405  \n",
       "...        ...       ...  \n",
       "1070  0.010814  0.027298  \n",
       "1071  0.012310  0.006221  \n",
       "1072  0.011262  0.006253  \n",
       "1073  0.029094  0.012111  \n",
       "1074  0.013560  0.007205  \n",
       "\n",
       "[1075 rows x 16 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
