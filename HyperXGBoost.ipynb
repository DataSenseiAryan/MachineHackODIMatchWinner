{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../MachineHackODIMatchWinner/Train.csv\")\n",
    "test = pd.read_csv(\"../MachineHackODIMatchWinner/Test.csv\")\n",
    "\n",
    "#sf = pd.read_excel(\"../MachinehackGlassQualityPrediction/Glass_Quality_Participants_Data/Sample_Submission.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = train.shape[0]\n",
    "train['isTrain'] =1\n",
    "test['MatchWinner'] =-1\n",
    "test['isTrain'] =0\n",
    "\n",
    "data = pd.concat([train,test],axis=0,sort = False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2508, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1075, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/ryan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data['Home2Inning'] = 'OH yeah'\n",
    "for i in data.index:\n",
    "    if(data['Team1_Venue'][i] == 'Home' and data['Team1_Innings'][i]=='Second'):\n",
    "            data['Home2Inning'][i] ='Yes'\n",
    "    else:\n",
    "            data['Home2Inning'][i] = 'No'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/ryan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "data['Neutral2Inning'] = 'foo'\n",
    "\n",
    "for i in data.index:\n",
    "    if(data['Team1_Venue'][i] == 'Neutral' and data['Team1_Innings'][i]=='Second'):\n",
    "            data['Neutral2Inning'][i] = 'Yes'\n",
    "    else:\n",
    "            data['Neutral2Inning'][i] = 'No'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/ryan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data['Away2Inning'] = 'foo'\n",
    "for i in data.index:\n",
    "    if(data['Team1_Venue'][i] == 'Home' and data['Team1_Innings'][i]=='Second'):\n",
    "            data['Away2Inning'][i] ='Yes'\n",
    "    else:\n",
    "            data['Away2Inning'][i] ='No'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  data.drop(['Stadium','Team2_Innings','Team2_Venue'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data['isTrain']==1]\n",
    "test = data[data['isTrain']==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['isTrain'],axis=1)\n",
    "test = test.drop(['MatchWinner', 'isTrain'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onhotencoder(train,test,cols):\n",
    "    \n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    #object_cols = catVar1(train) #catVar1 gives desired categorical column and not all object columns\n",
    "    object_cols=cols\n",
    "    print(object_cols)\n",
    "    \n",
    "    OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train[object_cols]))\n",
    "    OH_cols_test = pd.DataFrame(OH_encoder.transform(test[object_cols]))\n",
    "\n",
    "    # One-hot encoding removed index; put it back\n",
    "    OH_cols_train.index = train.index\n",
    "    OH_cols_test.index = test.index\n",
    "\n",
    "    ##hack for restoring columns names just like get dummies\n",
    "    column_name = OH_encoder.get_feature_names(object_cols)\n",
    "    OH_cols_train.columns = column_name\n",
    "    OH_cols_test.columns = column_name\n",
    "    \n",
    "\n",
    "    # Remove desired categorical columns (will replace with one-hot encoding)\n",
    "    num_train = train.drop(object_cols, axis=1)\n",
    "    num_test = test.drop(object_cols, axis=1)\n",
    "\n",
    "    # Add one-hot encoded columns to numerical/remaining features\n",
    "    OH_train = pd.concat([num_train, OH_cols_train], axis=1)\n",
    "    OH_test = pd.concat([num_test, OH_cols_test], axis=1)\n",
    "    \n",
    "    print(OH_train.shape,OH_test.shape)\n",
    "    \n",
    "    \n",
    "    return OH_train,OH_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Team1', 'Team2', 'HostCountry', 'Team1_Venue', 'Team1_Innings',\n",
       "       'MonthOfMatch', 'MatchWinner', 'Home2Inning', 'Neutral2Inning',\n",
       "       'Away2Inning'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Team1', 'Team2', 'HostCountry', 'Team1_Venue', 'Team1_Innings',\n",
       "       'MonthOfMatch', 'MatchWinner', 'Home2Inning', 'Neutral2Inning',\n",
       "       'Away2Inning'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Team1_Venue', 'Team1_Innings', 'MonthOfMatch', 'Home2Inning', 'Neutral2Inning', 'Away2Inning']\n",
      "(2508, 27) (1075, 26)\n"
     ]
    }
   ],
   "source": [
    "trainlblohe ,testlblohe = onhotencoder(train,test, cols = [ 'Team1_Venue', 'Team1_Innings','MonthOfMatch','Home2Inning','Neutral2Inning','Away2Inning']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from ngboost.distns import k_categorical\n",
    "from ngboost.learners import default_tree_learner\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'n_estimators':[50,80,100,125,150,175],\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'learning_rate': [0.1,0.2,0.3,0.4,0.5]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier( objective='multi:softprob',\n",
    "                    silent=True, nthread= -1, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = trainlblohe.MatchWinner\n",
    "\n",
    "# To keep things simple, we'll use only numerical predictors\n",
    "X = trainlblohe.drop(['MatchWinner'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folds = 5\n",
    "# param_comb = 20\n",
    "# sss = StratifiedShuffleSplit(n_splits=10, test_size=0.4, random_state=3)\n",
    "# sss.get_n_splits(X, y)\n",
    "\n",
    "# random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='neg_log_loss', n_jobs=-1, cv=sss, verbose=3, random_state=1001 )\n",
    "\n",
    "# random_search.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print('\\n All results:')\n",
    "# # print(random_search.cv_results_)\n",
    "# # print('\\n Best estimator:')\n",
    "#  print(random_search.best_estimator_)\n",
    "# # print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "# # print(random_search.best_score_ * 2 - 1)\n",
    "# # print('\\n Best hyperparameters:')\n",
    "#  print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "        'n_estimators':[110,118,125,130,135],\n",
    "        'min_child_weight': [0.5,1, 1.5,2,3],\n",
    "        'gamma': [0.3,0.4,0.5,0.7],\n",
    "        'subsample': [0.9, 1.0,1.1,1.2],\n",
    "        'colsample_bytree': [0.5,0.6,0.7],\n",
    "        'learning_rate': [0.2,0.25]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2400 candidates, totalling 24000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   42.7s\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 541 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 861 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1216 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1648 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2192 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2785 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3509 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4270 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5144 tasks      | elapsed: 28.8min\n",
      "[Parallel(n_jobs=-1)]: Done 6048 tasks      | elapsed: 33.9min\n",
      "[Parallel(n_jobs=-1)]: Done 7008 tasks      | elapsed: 39.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8084 tasks      | elapsed: 45.6min\n",
      "[Parallel(n_jobs=-1)]: Done 9168 tasks      | elapsed: 52.4min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-eb549580561d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_log_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folds = 5\n",
    "param_comb = 20\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.4, random_state=3)\n",
    "sss.get_n_splits(X, y)\n",
    "\n",
    "grid_search = GridSearchCV(xgb, param_grid=params_grid, scoring='neg_log_loss', n_jobs=-1, cv=sss, verbose=3 )\n",
    "\n",
    "grid_search.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of GridSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=3, test_size=0.4,\n",
       "            train_size=None),\n",
       "             error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     nthread=-1...\n",
       "                                     scale_pos_weight=1, seed=None, silent=True,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.5, 0.6, 0.7],\n",
       "                         'gamma': [0.3, 0.4, 0.5, 0.7],\n",
       "                         'learning_rate': [0.2, 0.25],\n",
       "                         'min_child_weight': [0.5, 1, 1.5, 2, 3],\n",
       "                         'n_estimators': [110, 118, 125, 130, 135],\n",
       "                         'subsample': [0.9, 1.0, 1.1, 1.2]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_log_loss', verbose=3)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=2.3886 val_loss=0.0000 scale=0.5000 norm=9.4365\n",
      "[iter 100] loss=1.4553 val_loss=0.0000 scale=1.0000 norm=5.6311\n",
      "[iter 200] loss=0.9715 val_loss=0.0000 scale=1.0000 norm=3.6072\n",
      "[iter 300] loss=0.8678 val_loss=0.0000 scale=1.0000 norm=3.3070\n",
      "[iter 400] loss=0.8126 val_loss=0.0000 scale=1.0000 norm=3.1493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NGBClassifier(Base=DecisionTreeRegressor(ccp_alpha=0.0,\n",
       "                                         criterion='friedman_mse', max_depth=3,\n",
       "                                         max_features=None, max_leaf_nodes=None,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_impurity_split=None,\n",
       "                                         min_samples_leaf=1,\n",
       "                                         min_samples_split=2,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         presort='deprecated',\n",
       "                                         random_state=None, splitter='best'),\n",
       "              Dist=<class 'ngboost.distns.categorical.k_categorical.<locals>.Categorical'>,\n",
       "              Score=<class 'ngboost.scores.LogScore'>, learning_rate=0.01,\n",
       "              minibatch_frac=1.0, n_estimators=500, natural_gradient=True,\n",
       "              random_state=RandomState(MT19937) at 0x7F4CB371EDB0, tol=0.0001,\n",
       "              verbose=True, verbose_eval=100)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ngboost import NGBClassifier\n",
    "from ngboost.distns import k_categorical\n",
    "from ngboost.learners import default_tree_learner\n",
    "clf2 = NGBClassifier(random_state=2,Dist=k_categorical(16))\n",
    "clf2.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '(array([ 453,  154, 1701, ...,  816,  893,  451]), slice(None, None, None))' is an invalid key\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '(array([1500,  154,  989, ..., 1903,  816,  893]), slice(None, None, None))' is an invalid key\n",
      "\n",
      "  FitFailedWarning)\n",
      "/home/ryan/.local/lib/python3.6/site-packages/ngboost/distns/categorical.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log(self.probs[Y, range(len(Y))])\n",
      "/home/ryan/.local/lib/python3.6/site-packages/ngboost/distns/categorical.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.log(self.probs[Y, range(len(Y))])\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '(array([ 453,  154, 1701, ...,  816,  893,  451]), slice(None, None, None))' is an invalid key\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '(array([1500,  154,  989, ..., 1903,  816,  893]), slice(None, None, None))' is an invalid key\n",
      "\n",
      "  FitFailedWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:788: RuntimeWarning: invalid value encountered in subtract\n",
      "  array_means[:, np.newaxis]) ** 2,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Base': Ridge(alpha=0.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001), 'minibatch_frac': 1.0, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "from ngboost.distns import k_categorical\n",
    "from ngboost import NGBClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "b1 = DecisionTreeRegressor(criterion=\"friedman_mse\", max_depth=2)\n",
    "b2 = DecisionTreeRegressor(criterion=\"friedman_mse\", max_depth=4)\n",
    "b3 = Ridge(alpha=0.0)\n",
    "b4 = XGBClassifier(random_state=2)\n",
    "b5 = LGBMClassifier(random_state=2)\n",
    "\n",
    "param_grid = {\n",
    "        \"n_estimators\": [20, 50],\n",
    "        \"minibatch_frac\": [1.0, 0.5],\n",
    "        \"Base\": [b1,b3],\n",
    "    }\n",
    "\n",
    "ngb = NGBClassifier(natural_gradient=True, verbose=False, Dist=k_categorical(16))\n",
    "\n",
    "grid_search = GridSearchCV(ngb, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X, y)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    \n",
    "    from xgboost import XGBClassifier\n",
    "    from ngboost.distns import k_categorical\n",
    "    from ngboost.learners import default_tree_learner\n",
    "    from sklearn.metrics import log_loss\n",
    "    \n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from ngboost import NGBClassifier\n",
    "    from sklearn.ensemble import BaggingClassifier\n",
    "    from lightgbm import LGBMClassifier\n",
    "    from sklearn.calibration import CalibratedClassifierCV\n",
    "    from sklearn.model_selection import StratifiedKFold, KFold,StratifiedShuffleSplit\n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "         \n",
    "    \n",
    "    clf2 = XGBClassifier(random_state=2)\n",
    "    \n",
    "    #clf2 = NGBClassifier(random_state=2,Dist=k_categorical(16))\n",
    "    \n",
    "    clf2.fit(X_train,y_train)\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=10, test_size=0.4, random_state=3)\n",
    "    sss.get_n_splits(X_train, y_train)\n",
    "    \n",
    "    clf_sigmoid = CalibratedClassifierCV(clf2, cv=sss, method='isotonic')\n",
    "    clf_sigmoid.fit(X_train, y_train)\n",
    "    preds = clf_sigmoid.predict_proba(X_valid)\n",
    "    preds1 = clf_sigmoid.predict(X_valid)\n",
    "\n",
    "#     preds1 = clf2.predict(X_valid)\n",
    "#     preds = clf2.predict_proba(X_valid)\n",
    "    target_names = ['class 0', 'class 1', 'class 2','class 3', 'class 4', 'class 5', 'class 6',\n",
    "                    'class 7', 'class 8', 'class 9','class 10', 'class 11', 'class 12', 'class 13',\n",
    "                    'class 14', 'class 15']\n",
    "    #print(preds)\n",
    "    print(classification_report(y_valid, preds1, target_names=target_names,labels= [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]))\n",
    "    return log_loss(y_valid,preds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### from sklearn.model_selection import train_test_split\n",
    "y = trainlblohe.MatchWinner\n",
    "\n",
    "# To keep things simple, we'll use only numerical predictors\n",
    "X = trainlblohe.drop(['MatchWinner'], axis=1)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.57, test_size=0.43,random_state=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
